{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49b08b47",
   "metadata": {},
   "source": [
    "[Chapter 7] Fine-tuning to follow instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc43311d",
   "metadata": {},
   "source": [
    "preparing dataset for supervised instruction fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26fd1983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    return data\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6d05ecd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"example entry:\\n\", data[50])\n",
    "# python dictionary objects containing \"instruction\", \"input\" and \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d247612e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"another example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c4c829a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt formatting function\n",
    "\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = (\n",
    "        f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    )\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9e15b44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response: \n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response: \\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "311a7b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response: \n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response: \\n{data[999]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bc901505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set length: 935\n",
      "validation set length: 55\n",
      "test set length: 110\n"
     ]
    }
   ],
   "source": [
    "# partitioning the dataset\n",
    "\n",
    "# use 85% data for training\n",
    "train_portion = int(len(data) * 0.85)\n",
    "# use 10% data for testing\n",
    "test_portion = int(len(data) * 0.1)\n",
    "# use remaining 5% for vaidation\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "\n",
    "print(\"training set length:\", len(train_data))\n",
    "print(\"validation set length:\", len(val_data))\n",
    "print(\"test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310ef8d4",
   "metadata": {},
   "source": [
    "organizing data into training batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1139b15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            # pretokenize texts\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(tokenizer.encode(full_text))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9f49e6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7ed90384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(batch, pad_token_id=50256, device='cpu'):\n",
    "    # find the longest sequence in the batch (while allowing diff batches have diff length)\n",
    "    batch_max_length = max(len(item) + 1 for item in batch)\n",
    "    inputs_lst = []\n",
    "    # pad and prepare inputs\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # remove extra padded token added earlier\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "    \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b6613a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "# test and verify\n",
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "12d5ff98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "def custom_collate_draft_2(\n",
    "        batch,\n",
    "        pad_token_id=50256,\n",
    "        device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (new_item + [pad_token_id] * (batch_max_length - len(new_item)))\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        # similar toe the process we used to pretrain LLM\n",
    "        # target token ids match the input token ids but are shifted one position to the right \n",
    "        targets = torch.tensor(padded[1:])\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor\n",
    "\n",
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1f62fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom batch collate function\n",
    "def custom_collate_fn(batch, pad_token_id=50256, ignore_index=-100, allowed_max_length=None, device='cpu'):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        # pad sequence to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # truncate the last token for inputs (given end with 50256 even before padded)\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        # shift +1 to the right for targets\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        \n",
    "        # replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id  # 1 if pad_token_id \n",
    "        indices = torch.nonzero(mask).squeeze()  \n",
    "        if indices.numel() > 1:\n",
    "            # assign -100 value to all padding tokens: allow us to exclude these padding tokens from contirbuting to the training loss calculation\n",
    "            #                                          no need to fine-tune for classificaiton given training is only based on last ouput token \n",
    "            # reain one 50256 in the target list to allow LLM to learn when to generate an end-of-text token in repsonse to instruction\n",
    "            targets[indices[1:]] = ignore_index\n",
    "        \n",
    "        # optionally truncate to the max sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    \n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "db4184ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "# test and try\n",
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e7fd468c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0], # predictions for 1st token\n",
    "     [-0.5, 1.5]] # predictions for 2nd token\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1]) # actual/correct token indices to generate\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6df54db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "# adding an additional token id affects the loss calculation\n",
    "\n",
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2160fff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "# if we replace the third target token id with -100\n",
    "\n",
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)\n",
    "\n",
    "# corss entropy loss func igonored the third entry of -100\n",
    "# masking out insturctions: besides masking out padding tokens, also common to mask out the target token ids corresponding to instructions.\n",
    "#                           the cross entropy then only compute for the generated response target ids\n",
    "#                           the model is trained to focus on generating accruate response not memorizing instructions (reducing overfiting)\n",
    "#                           however, research shows not masking the instructions benefitting the LLM performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f8e08",
   "metadata": {},
   "source": [
    "creating data loaders from an instruction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d00397aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# uncomment below two lines to use the gpu on apple silicon chip\n",
    "# if torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "45d8e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new version of the function with the device argument prefilled\n",
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f864c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0 # can increase this number if parallel python processes are suported by os\n",
    "                # adapted to specific dataset ize and computation environment\n",
    "                # set num_workers=4 usually leads to optimal performance\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "16f784e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)\n",
    "\n",
    "# 8 represents the batch size, 62 is the number of tokens in each training example\n",
    "# able to create batches of different lengths (thanks to custom collate func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9125edfa",
   "metadata": {},
   "source": [
    "loading a pretrained LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b872c1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "\n",
    "import import_ipynb\n",
    "from ch4 import GPTModel\n",
    "from ch5 import load_weights_into_gpt\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,       # vocab size\n",
    "    \"context_length\": 1024,    # context length\n",
    "    \"drop_rate\": 0.0,          # dorpout rate\n",
    "    \"qkv_bias\": True           # query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-x1 (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\" # different with book, to save some time given my hardware contraint, i use small model here\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir='gpt2'\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7521046b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7636ee8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nConvert the active sentence to passive: 'The chef cooks the meal every day.'\\n\\n### Response:\\nThe chef cooks the meal every day.\""
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ch5 import generate, text_to_token_ids, token_ids_to_text\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f061475a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "The chef cooks the meal every day.\n"
     ]
    }
   ],
   "source": [
    "# isolate model's reponse text\n",
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(response_text)\n",
    "\n",
    "# the result shows that the pretrained model is not yet capable of correctly following the given instruction\n",
    "# it simply repeats the original input sentence and part of the instruction, failing to convert the active sentence to passive voice as requested"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf50cddf",
   "metadata": {},
   "source": [
    "Fine-tuning the LLM on instruction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c17a16e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ch5 import(\n",
    "    calc_loss_loader,\n",
    "    train_model_simple\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3935a900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.4401358664035797\n",
      "validation loss: 0.7419604539871216\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# torch.no_grad means we use the model for inference only (no need to keep track of gradients, use a network without training or backpropagation)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(\n",
    "        train_loader, model, device, num_batches=5\n",
    "    )\n",
    "    val_loss = calc_loss_loader(\n",
    "        val_loader, model, device, num_batches=5\n",
    "    )\n",
    "\n",
    "print(\"training loss:\", train_loss)\n",
    "print(\"validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "13dc3b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step  00000):train loss  3.119 ,val loss  3.069\n",
      "Ep 1 (Step  00005):train loss  1.696 ,val loss  1.570\n",
      "Ep 1 (Step  00010):train loss  1.096 ,val loss  1.164\n",
      "Ep 1 (Step  00015):train loss  1.053 ,val loss  1.083\n",
      "Ep 1 (Step  00020):train loss  0.970 ,val loss  1.038\n",
      "Ep 1 (Step  00025):train loss  0.919 ,val loss  1.002\n",
      "Ep 1 (Step  00030):train loss  0.960 ,val loss  0.978\n",
      "Ep 1 (Step  00035):train loss  0.877 ,val loss  0.951\n",
      "Ep 1 (Step  00040):train loss  0.847 ,val loss  0.943\n",
      "Ep 1 (Step  00045):train loss  0.777 ,val loss  0.925\n",
      "Ep 1 (Step  00050):train loss  0.869 ,val loss  0.911\n",
      "Ep 1 (Step  00055):train loss  0.923 ,val loss  0.893\n",
      "Ep 1 (Step  00060):train loss  0.872 ,val loss  0.877\n",
      "Ep 1 (Step  00065):train loss  0.800 ,val loss  0.867\n",
      "Ep 1 (Step  00070):train loss  0.694 ,val loss  0.860\n",
      "Ep 1 (Step  00075):train loss  0.706 ,val loss  0.855\n",
      "Ep 1 (Step  00080):train loss  0.753 ,val loss  0.847\n",
      "Ep 1 (Step  00085):train loss  0.680 ,val loss  0.836\n",
      "Ep 1 (Step  00090):train loss  0.729 ,val loss  0.827\n",
      "Ep 1 (Step  00095):train loss  0.652 ,val loss  0.821\n",
      "Ep 1 (Step  00100):train loss  0.634 ,val loss  0.808\n",
      "Ep 1 (Step  00105):train loss  0.728 ,val loss  0.803\n",
      "Ep 1 (Step  00110):train loss  0.718 ,val loss  0.799\n",
      "Ep 1 (Step  00115):train loss  0.672 ,val loss  0.796\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.### Instruction:Convert the active sentence to passive: 'The chef cooks the meal every day.'### Response:The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.### Input:The following is a sentence.### Response\n",
      "Ep 2 (Step  00120):train loss  0.591 ,val loss  0.790\n",
      "Ep 2 (Step  00125):train loss  0.625 ,val loss  0.801\n",
      "Ep 2 (Step  00130):train loss  0.583 ,val loss  0.789\n",
      "Ep 2 (Step  00135):train loss  0.546 ,val loss  0.791\n",
      "Ep 2 (Step  00140):train loss  0.579 ,val loss  0.789\n",
      "Ep 2 (Step  00145):train loss  0.518 ,val loss  0.785\n",
      "Ep 2 (Step  00150):train loss  0.520 ,val loss  0.781\n",
      "Ep 2 (Step  00155):train loss  0.594 ,val loss  0.785\n",
      "Ep 2 (Step  00160):train loss  0.585 ,val loss  0.785\n",
      "Ep 2 (Step  00165):train loss  0.537 ,val loss  0.781\n",
      "Ep 2 (Step  00170):train loss  0.440 ,val loss  0.775\n",
      "Ep 2 (Step  00175):train loss  0.479 ,val loss  0.769\n",
      "Ep 2 (Step  00180):train loss  0.540 ,val loss  0.760\n",
      "Ep 2 (Step  00185):train loss  0.567 ,val loss  0.757\n",
      "Ep 2 (Step  00190):train loss  0.442 ,val loss  0.742\n",
      "Ep 2 (Step  00195):train loss  0.469 ,val loss  0.729\n",
      "Ep 2 (Step  00200):train loss  0.408 ,val loss  0.728\n",
      "Ep 2 (Step  00205):train loss  0.480 ,val loss  0.724\n",
      "Ep 2 (Step  00210):train loss  0.516 ,val loss  0.725\n",
      "Ep 2 (Step  00215):train loss  0.539 ,val loss  0.734\n",
      "Ep 2 (Step  00220):train loss  0.413 ,val loss  0.738\n",
      "Ep 2 (Step  00225):train loss  0.487 ,val loss  0.738\n",
      "Ep 2 (Step  00230):train loss  0.425 ,val loss  0.742\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.### Instruction:Convert the active sentence to passive: 'The chef cooks the meal every day.'### Response:The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.### Input:What is the chemical symbol for carbon?\n",
      "training completed in 26.96 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=0.00005, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5dfb6785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "from ch5 import plot_losses\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n",
    "# the result indicates that the training is effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c85409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a horse.\n",
      "---------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud typically associated with thunderstorms is a tropical rainforest.\n",
      "---------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Robert Frost.\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# iterate over the first three test set samples\n",
    "for entry in test_data[:3]:\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"---------------------------------\")\n",
    "\n",
    "    # based on the results, the model performs relatively well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0973acc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [05:22<00:00,  2.94s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    # indent for pretty printing\n",
    "    json.dump(test_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "89cc5fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a horse.'}\n"
     ]
    }
   ],
   "source": [
    "# verify: the responses have been added the test_set \n",
    "print(test_data[0])\n",
    "\n",
    "# the output shows that the model responses have been added correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c779b6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode saved as gpt2-small124M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "import re\n",
    "\n",
    "# remove white space and parentheses from filename\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL)}-sft.pth\"\n",
    "torch.save(model.state_dict(),file_name)\n",
    "print(f\"Mode saved as {file_name}\")\n",
    "\n",
    "# the saved model can be loaded via below\n",
    "# model.load_state_dict(torch.load(\"gpt2-small124M-sft.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a607b7f",
   "metadata": {},
   "source": [
    "Evaluate the fine-tuned LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb86e4e",
   "metadata": {},
   "source": [
    "automated conversational benchmarks: evaluate responses auomatically using another LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c2d8581d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "# with ollama session running on background\n",
    "import psutil\n",
    "\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter(['name']):\n",
    "        if process_name in proc.info['name']:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running('ollama')\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Launch ollama before processing.\")\n",
    "\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3f3e6d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# querying a local Ollama model\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "def query_model(\n",
    "        prompt,\n",
    "        model='llama3',\n",
    "        url=\"http://localhost:11434/api/chat\"\n",
    "):\n",
    "    # create data payload as a dictionary\n",
    "    data = {\"model\": model,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            # setttings for deterministic responses\n",
    "            \"options\": {\"seed\": 123, \"temperature\": 0, \"num_ctx\": 2048}}\n",
    "    \n",
    "    # convert the dict to a json-formatted string and encode it to bytes\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "    # create a request object, setting method to POST and add necessay headers\n",
    "    request = urllib.request.Request(\n",
    "        url,\n",
    "        data=payload,\n",
    "        method='POST'\n",
    "    )        \n",
    "\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "\n",
    "    # send the request and capture the response\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "    \n",
    "    return response_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "085e0033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are herbivores, which means they primarily feed on plant-based foods. Their diet typically consists of:\n",
      "\n",
      "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and even weeds.\n",
      "2. Hay: High-quality hay, such as alfalfa or timothy hay, is a staple in a llama's diet. They enjoy the sweet taste and texture of fresh hay.\n",
      "3. Grains: Llamas may receive grains like oats, barley, or corn as part of their daily ration. However, it's essential to provide these grains in moderation, as they can be high in calories.\n",
      "4. Fruits and vegetables: Llamas enjoy a variety of fruits and veggies, such as apples, carrots, sweet potatoes, and leafy greens like kale or spinach.\n",
      "5. Minerals: Llamas require access to mineral supplements, which help maintain their overall health and digestive system.\n",
      "\n",
      "In the wild, llamas might also eat:\n",
      "\n",
      "1. Leaves: They'll munch on leaves from trees and shrubs, like willow or cedar.\n",
      "2. Bark: In some cases, llamas may eat the bark of certain trees, like aspen or birch.\n",
      "3. Mosses: Llamas have been known to graze on mosses and other non-woody plant material.\n",
      "\n",
      "In captivity, llama owners typically provide a balanced diet that includes a mix of hay, grains, and fruits/vegetables. It's essential to consult with a veterinarian or experienced llama breeder to determine the best feeding plan for your llama.\n"
     ]
    }
   ],
   "source": [
    "# test and try\n",
    "\n",
    "model = \"llama3\"\n",
    "result = query_model(\"What does Llamas eat?\", model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5541e54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a horse.\n",
      "\n",
      "Score:\n",
      ">> To evaluate the model's response, I'll compare it to the expected output and consider factors such as relevance, coherence, and overall quality.\n",
      "\n",
      "Expected output: The car is as fast as lightning.\n",
      "Model response: The car is as fast as a horse.\n",
      "\n",
      "Score: 60\n",
      "\n",
      "Reasoning:\n",
      "\n",
      "* Relevance: The model's response is somewhat relevant to the original sentence, as it attempts to compare the car's speed to that of an animal. However, using a horse as a comparison is not as striking or evocative as lightning.\n",
      "* Coherence: The model's response is coherent and easy to understand, but it may not be as vivid or memorable as the expected output.\n",
      "* Overall quality: While the model's response is not bad, it could be improved by choosing a more unexpected or surprising comparison that better captures the essence of the original sentence.\n",
      "\n",
      "To achieve a higher score, the model could consider using more creative and unexpected comparisons that better capture the speed and power of the car. For example:\n",
      "\n",
      "* The car is as fast as a cheetah on steroids.\n",
      "* The car is as fast as a bullet train.\n",
      "* The car is as fast as a speeding bullet.\n",
      "\n",
      "By incorporating more vivid and evocative language, the model's response could be improved to achieve a higher score.\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud typically associated with thunderstorms is a tropical rainforest.\n",
      "\n",
      "Score:\n",
      ">> I'd rate this model response a 0 out of 100.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The instruction asks about the type of cloud associated with thunderstorms.\n",
      "* The model response mentions \"tropical rainforest\", which has nothing to do with clouds or thunderstorms.\n",
      "* A tropical rainforest is a type of ecosystem, not a type of cloud. Cumulonimbus clouds are the correct answer.\n",
      "\n",
      "The model response is completely off-topic and incorrect, so it deserves a score of 0.\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Robert Frost.\n",
      "\n",
      "Score:\n",
      ">> A nice simple question!\n",
      "\n",
      "### Model Response:\n",
      "The author of 'Pride and Prejudice' is Robert Frost.\n",
      "\n",
      "### Score: 0/100\n",
      "\n",
      "Why? Because Robert Frost was an American poet, not a novelist, and he did not write 'Pride and Prejudice'. The correct answer is Jane Austen, an English novelist known for her works of romantic fiction, including 'Pride and Prejudice'.\n",
      "\n",
      "The model response is completely incorrect, so it scores 0 out of 100.\n",
      "\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "for entry in test_data[:3]:\n",
    "    prompt = (\n",
    "        f\"Given the input '{format_input(entry)}'\"\n",
    "        f\"and correct output '{entry['output']}', \"\n",
    "        f\"score the model response '{entry['model_response']}'\"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score.\"\n",
    "    )\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry['model_response'])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", query_model(prompt))\n",
    "    print(\"\\n-----------------------------------\")\n",
    "\n",
    "# the generated response show that the Llama 3 model provides reasonable evaluations\n",
    "# and is capable of assigning partial points when a model's answer is not entirely correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4e4f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|██████████| 110/110 [30:46<00:00, 16.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 110 of 110\n",
      "Average score: 39.19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# modify the prompt to just generate integer scores raning from 0 to 100\n",
    "\n",
    "def generate_model_scores(json_data, json_key, model='llama3'):\n",
    "    scores=[]\n",
    "    for entry in tqdm(json_data, desc='Scoring entries'):\n",
    "        # modified instruction line to only return the score\n",
    "        prompt = (\n",
    "            f\"Given the input '{format_input(entry)}'\"\n",
    "            f\"and correct output '{entry['output']}', \"\n",
    "            f\"score the model response '{entry['model_response']}'\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score.\"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores) / len(scores):.2f}\\n\")\n",
    "# the average score is relatively low at 39.19 (vs. 50.32 using meidum model in book)\n",
    "\n",
    "# the average score provides a useful benchmark for comparison against other models \n",
    "# (or for experimenting with different training configuarion to improve the model's performance)\n",
    "\n",
    "# Ollama is not entirely deterministic: the scores you obtain might vary slightly from the previous scores\n",
    "#                                       to obtain more robust results, can repeat the evaluation multiple times and average the resulting scores\n",
    "\n",
    "# to futher improve model performance:\n",
    "# - adjust the hyperparameters during fine-tunning\n",
    "# - increase the size of the training dataset or diversifying the examples to cover a broader range of topics and styles\n",
    "# - experiement different prompts or instruction ormats\n",
    "# - use a larger pretrained model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
