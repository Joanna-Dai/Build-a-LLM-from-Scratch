{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4d8d458",
   "metadata": {},
   "source": [
    "[Chapter 4] Building an LLM - LLM Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5cabc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\":     50257,     # vocabulary size (by BPE tokenizer)\n",
    "    \"context_length\": 1024,      # context length (max token size model can handle)\n",
    "    \"emb_dim\":        768,       # embedding dimension (tranform each token into a 768-dimensional vector)\n",
    "    \"n_heads\":        12,        # number of head attentions (num of attention heads in the multi-head attention mechanism)\n",
    "    \"n_layers\":       12,        # number of layers (num of transformer blocks in the model)\n",
    "    \"drop_rate\":      0.1,       # dropout rate (the intensity of dropout mechanism to prevent overfitting)\n",
    "    \"qkv_bias\":       False      # query-key-value bias (whether to include a bias vector in the linear layers of the mha)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c957349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        # token embeddings\n",
    "        self.tok_emb = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
    "        # positional embeddings\n",
    "        self.pos_emb = nn.Embedding(cfg['context_length'], cfg['emb_dim'])\n",
    "        # dropout\n",
    "        self.drop_emb = nn.Dropout(cfg['drop_rate'])\n",
    "        # transformer block\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            * [DummyTransformerBlock(cfg)\n",
    "               for _ in range(cfg['n_layers'])]\n",
    "        )\n",
    "        # normalization layer\n",
    "        # adjust activations (outputs) of a nn layerto have a mean of 0 and a variance of 1(unit variance)\n",
    "        # to speed up the convergence to effective weights and ensures consistent and reliable training\n",
    "        self.final_norm = DummyLayerNorm(cfg['emb_dim'])\n",
    "        # linear output layer\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg['emb_dim'], cfg['vocab_size'], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "# a simple placeholder class that will be replaced by a real transformerblock later\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "# a simple placeholder calss that will be replaced by a real layernorm later\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50dc27d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],\n",
      "         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],\n",
      "         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],\n",
      "         [ 0.0139,  1.6754, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],\n",
      "\n",
      "        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],\n",
      "         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],\n",
      "         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],\n",
      "         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model =  DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "# [2, 4, 50257] = 2 rows(input texts), 4 tokens, 50257 dimensions for each token\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7564dcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "# creates 2 training examples with 5 dimensions/features each\n",
    "batch_example = torch.randn(2, 5)\n",
    "# neural network layer with 5 inputs and 6 outputs\n",
    "# linear layer with non-linear activation function ReLU (rectified linear unit, thresholds -ve inputs to 0, ensure only +ve values)\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "576f147f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "variance:\n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "# keepdim=True ensures the output tensor retains the same dim of input tensor\n",
    "# dim = 1 or -1 calculates means across column dimension to obtain one mean per row \n",
    "# (1 and -1 are same here given it's a 2-dimension tensor)\n",
    "# dim = 0 calculates mean across the row dmension to obtain one mean per column\n",
    "print(\"mean:\\n\", mean)\n",
    "print(\"variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2e3233",
   "metadata": {},
   "source": [
    "layer normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df00ab0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized layer outputs:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "mean:\n",
      " tensor([[    0.0000],\n",
      "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
      "variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# apply layer normalization to the layer outputs\n",
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"normalized layer outputs:\\n\", out_norm)\n",
    "print(\"mean:\\n\", mean)\n",
    "print(\"variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42324656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:\n",
      " tensor([[    0.0000],\n",
      "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
      "variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# turn off scientific notation\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"mean:\\n\", mean)\n",
    "print(\"variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca2725bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False) #does not apply bessel's correction (using n not n-1)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64af01ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb3303c",
   "metadata": {},
   "source": [
    "feed forward network with activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ef51f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return 0.5*x*(1+torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            ( x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a99e7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GELU vs. ReLU\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "plt.figure(figsize=(8, 3))\n",
    "\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ReLU: piecewise linear function, outputs input directly if it is positive, otherwise outputs zero\n",
    "# sharp corner at zero, makes optimization harder, esp. in networks that are very deep or have have complex architecture\n",
    "\n",
    "\n",
    "# GELU: smooth nonlinear function, approximates ReLU but with a non-zero gradient (steepness) for almost all negative values (except at around x=-0.75)\n",
    "# smoothness leads to better optimization as it allows for more nuanced adjustments to the model's paramters\n",
    "# allows for a small, non-zero output for negative values. \n",
    "# (that means, neurons that receive negative input can still contribute to the learning process, though to a lesser extent than positive inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8867aa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input (2-batch size, 3-num of tokens, 768-embedding size)\n",
    "# the first layer increases the embedding dimension by a factor of 4\n",
    "# the second layer decreases the embedding dimension by a factor of 4\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg['emb_dim'], 4 * cfg['emb_dim']),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg['emb_dim'], cfg['emb_dim'])\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce1b203d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768)\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2a6758",
   "metadata": {},
   "source": [
    "shortcut/skip/residual connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d1b5729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            # output of the current layer\n",
    "            layer_output = layer(x)\n",
    "            # check if shortcut can be applied\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee85bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9eddbe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    # forward pass\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    # calculate loss based on how close the target and output are\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "\n",
    "    # backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "37b9963d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152041653171182\n",
      "layers.3.0.weight has gradient mean of 0.001398873864673078\n",
      "layers.4.0.weight has gradient mean of 0.005049646366387606\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input)\n",
    "\n",
    "# vanishing gradient problem: the gradients become smaller as progressing from layer.4 to layer.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8cfb150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f069ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169792652130127\n",
      "layers.1.0.weight has gradient mean of 0.20694106817245483\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732502937317\n",
      "layers.4.0.weight has gradient mean of 1.3258541822433472\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_with_shortcut, sample_input)\n",
    "\n",
    "# the gradient value stablizes as we progress toward layers.0 and doesn't shrink to a vanishingly small value\n",
    "# shortcut connections are important for overcoming the limitations posed by the vanishing gradient probelm in deep neural networks\n",
    "# shortcut connections facilitate more effective training by ensuring consistent gradient flow across layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5079163b",
   "metadata": {},
   "source": [
    "connecting attention and linear layers in a transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dfd4706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from ch3 import MultiHeadAttention\n",
    "\n",
    "# defines a transformerblock class that inlcudes \n",
    "# - multi-head attention mechanism (MultiHeadAttention)\n",
    "# - feed forward network (FeedFoward)\n",
    "# - configured based on provided configuration dictionary (cfg), such as GPT_CONFIG_124M\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in = cfg['emb_dim'],\n",
    "            d_out = cfg['emb_dim'],\n",
    "            context_length = cfg['context_length'],\n",
    "            num_heads = cfg['n_heads'],\n",
    "            dropout = cfg['drop_rate'],\n",
    "            qkv_bias= cfg['qkv_bias'])\n",
    "        \n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg['emb_dim'])\n",
    "        self.norm2 = LayerNorm(cfg['emb_dim'])\n",
    "        self.drop_shortcut = nn.Dropout(cfg['drop_rate'])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        # shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "04ec4372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([2, 4, 768])\n",
      "output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768)\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "\n",
    "print(\"input shape:\", x.shape)\n",
    "print(\"output shape:\", output.shape)\n",
    "\n",
    "# transformer architecture pocesses sequences of data without altering their shape throughout the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dc97c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        # embedding layers: convert input tokens indices into dense vectors and adding positional information\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        # transformer block: sequential stack of transformerblock meodules equal to the number of layers specified in cfg\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        # layer norm: standardizing outputs from the transformer blocks to stabilize the learning process\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "\n",
    "        # linear output head without bias: projects transformer's output into the vocabulary space of the tokenizer to generate logits\n",
    "        # logits: for each token in the vocabulary, representing the next token's unnormalized probabilities\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "    \n",
    "    # forward method: takes a batch of input token indices, computes their embeddings, applies the positional embeddings, \n",
    "    # passes the sequence through the transformer blocks, normalizes the final output\n",
    "    # computes the logits (representing the next token's unnormalized probabilities)\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        \n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ac77e8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Ouput shape: torch.Size([2, 4, 768])\n",
      "tensor([[[ 0.3613,  0.4222, -0.0711,  ...,  0.3483,  0.4661, -0.2838],\n",
      "         [-0.1792, -0.5660, -0.9485,  ...,  0.0477,  0.5181, -0.3168],\n",
      "         [ 0.7120,  0.0332,  0.1085,  ...,  0.1018, -0.4327, -0.2553],\n",
      "         [-1.0076,  0.3418, -0.1190,  ...,  0.7195,  0.4023,  0.0532]],\n",
      "\n",
      "        [[-0.2564,  0.0900,  0.0335,  ...,  0.2659,  0.4454, -0.6806],\n",
      "         [ 0.1230,  0.3653, -0.2074,  ...,  0.7705,  0.2710,  0.2246],\n",
      "         [ 1.0558,  1.0318, -0.2800,  ...,  0.6936,  0.3205, -0.3178],\n",
      "         [-0.1565,  0.3926,  0.3288,  ...,  1.2630, -0.1858,  0.0388]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOuput shape:\", output.shape)\n",
    "print(out)\n",
    "# output tensor has shape [2, 4, 50257], given 2 input texts, 4 tokens each, 50257 vocab size of tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "399c7d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"total number of parameters: {total_params:,}\")\n",
    "# 163mil parameter size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3c09a539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token embedding layer shape: torch.Size([50257, 768])\n",
      "output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d4f79ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of trainable parameters considering weight tying: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = (\n",
    "    total_params - sum(p.numel()\n",
    "                       for p in model.out_head.parameters())\n",
    ")\n",
    "\n",
    "print(f\"number of trainable parameters \"\n",
    "      f\"considering weight tying: {total_params_gpt2:,}\")\n",
    "\n",
    "# weight tying: original GPT-2 architecture resuses the weights from the token embedding layer in its output layer.\n",
    "# reduces the overall memory footprint and computational complexity of the model\n",
    "# now 124mil parameter large (matching original size of GPT2 model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e9f2d725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size of the model:  621.83 MB\n"
     ]
    }
   ],
   "source": [
    "# total size in bytes: assuming float32, 4 bytes per parameter\n",
    "total_size_bytes = total_params * 4\n",
    "\n",
    "# converts to megabytes\n",
    "total_size_mb = total_size_bytes / (1024*1024)\n",
    "print(f\"total size of the model: {total_size_mb: .2f} MB\")\n",
    "\n",
    "# memory requirements: assuming each parameter is a 32-bit float taking up 4 bytes, the total size of the model amounts to 621.83MB\n",
    "# illustrating the relatively large staorage capacity required to accomodate even relatively small LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eef4b50",
   "metadata": {},
   "source": [
    "generating text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "117c4dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        # crops current context if it exceeds the supported context size\n",
    "        # (i.e. if LLM supports only 5 tokens and the context size is 10, only the last 5 tokens are used as context)\n",
    "        idx_cond = idx[:, -context_size:] \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        # focus only on the last time step, (batch, n_token, vcab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]\n",
    "        # probas has shape (batch, vocab_size), softmax to convert logits into probability distribution\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        # idx_next has shape (batch, 1), argmax to identify the position with the highest prob value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        # appends sampled index to the runing sequence, where idx has shape (batch, n_tokens+1)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ade61502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded:  [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded: \", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0) # adds batch dimension\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9d29aaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval() # disables dropout since we are not training the model\n",
    "\n",
    "out = generate_text_simple(model=model, idx=encoded_tensor, max_new_tokens=6, context_size=GPT_CONFIG_124M[\"context_length\"])\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "256b23ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)\n",
    "# the reason the model unable to produce coherent text is that we haven't trained it yet\n",
    "# given we have only implemented the GPT architecture ad initialized a GPT model instance with initial random weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
