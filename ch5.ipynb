{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d45d42f",
   "metadata": {},
   "source": [
    "[Chapter 5] Pretraining on unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1db4f06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import import_ipynb\n",
    "from ch4 import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,  # shorten the context length from 1024 to 256\n",
    "                            # reduces the computational demand of training the model\n",
    "                            # making it possible to carry out the training on a standard laptop PC\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,      # it's possible and common to set dropout to 0\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af5b4bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from ch4 import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens = 10,\n",
    "    context_size = GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b6a0bc",
   "metadata": {},
   "source": [
    "calculating text generation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f04eb8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],  # every effort moves\n",
    "                       [40, 1107, 588]])     # i really like\n",
    "\n",
    "# targets are the inputs but shifted one position forward\n",
    "targets = torch.tensor([[3626, 6100, 345],   # effort moves you\n",
    "                        [1107, 588, 11311]]) # really like chocolates\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)\n",
    "\n",
    "# 2 - batch size (given 2 examples in the inputs)\n",
    "# 3 - # of tokens in each input(row)\n",
    "# 50257 - embedding dimensionality, determined by vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6eb1dfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ids:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"token ids:\\n\", token_ids)\n",
    "\n",
    "# given 2 input batches, each with 3 tokens, yields 2 sets of outputs, each with 3 predicted token IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3900089e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets batch 1:   effort moves you\n",
      "outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"targets batch 1:  {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"outputs batch 1: \"\n",
    "      f\"{token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb8d1302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 1:  tensor([    0.0001,     0.0000,     0.0000])\n",
      "text 2:  tensor([    0.0000,     0.0001,     0.0000])\n"
     ]
    }
   ],
   "source": [
    "# initial softmax prob\n",
    "\n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"text 1: \", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"text 2: \", target_probas_2)\n",
    "\n",
    "# the goal of training an LLM is to maximize the likelihood of the correct token (increasing its prob relative to other tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6ca310b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)\n",
    "\n",
    "# working with logarithms of probability scores is more manageable in mathematical opimization than handling the scores directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3740f511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n",
      "tensor(10.7940)\n",
      "logits shape:  torch.Size([2, 3, 50257])\n",
      "targets shape:  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)\n",
    "\n",
    "# the goal is to get the avg log prob as close to 0 as possible by updating te model's weight as part of the training process (backpropagation)\n",
    "# in deep learning, the common practice isn't to push the average log prob up to 0 but rather to bring the -ve avg log prob down to 0\n",
    "\n",
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)\n",
    "\n",
    "# cross entropy: the term for turning the -ve value -10.x into +10.x\n",
    "# pytorch has built-in cross_entropy function\n",
    "\n",
    "print(\"logits shape: \", logits.shape)\n",
    "print(\"targets shape: \", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b173c07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattened logits:  torch.Size([6, 50257])\n",
      "flattened targets:  torch.Size([6])\n",
      "tensor(10.7940)\n",
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1) # unscaled model outputs before they enter the softmax function to obtain prob scores\n",
    "targets_flat = targets.flatten()   # the token IDs we want the LLMs to generate\n",
    "print(\"flattened logits: \", logits_flat.shape)\n",
    "print(\"flattened targets: \", targets_flat.shape)\n",
    "\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)\n",
    "\n",
    "# perplexity measure how well the prob distribution predicted by the model matches the actual distribution of the words in the dataset\n",
    "# the lower the closer to actual distribution\n",
    "# considered more interpretable than the raw loss because it signifies the effective vocab size\n",
    "# 49064: model being unsure about which among 49064 tokens in the vocab to generate as the next token\n",
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d579f15",
   "metadata": {},
   "source": [
    "calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3af91376",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8771c531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characters: 20479\n",
      "tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"characters:\", total_characters)\n",
    "print(\"tokens:\", total_tokens) #5145 is too small to train, for educational purpose only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "feb4a711",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90 # define 90% training data and the remaining 10% as validation data\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[: split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "049d7370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from ch2 import create_dataloader_v1\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0   \n",
    ")\n",
    "\n",
    "print(\"train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nvalidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "# batch size = 2: we used small batch size to reduce computational resource demand because we were working with a very small dataset.\n",
    "#                 in practice, training LLMs with batch sizes of 1024 or larger is not uncommon.\n",
    "# 9 training set batches (2 samples and 256 tokens each) and 1 validation set (2 input examples and 256 tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76905a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss for a single batch\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    # the transfer to a given device allows us to transfer the data to a GPU\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1a2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss over all the batches sampled by a given data loader\n",
    "# num_batches: we can specify a smallre num_batches to speed up the evaluation during model training\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    \n",
    "    total_loss = 0.\n",
    "    \n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None: \n",
    "        #iteratives over all batches if no fixed num_batches is specified\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # reduces the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device \n",
    "            )\n",
    "            # sums loss for each batch\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return total_loss / num_batches  #average the loss over all batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16244d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 10.987583584255642\n",
      "validation loss: 10.981106758117676\n"
     ]
    }
   ],
   "source": [
    "# if machine with cuda-supported gpu, the LLM will train on the gpu without making any change to the code\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# disable gradient tracking for efficiency because we are not training yet\n",
    "with torch.no_grad():\n",
    "    # ensure the data is loaded onto the same device as LLM model via \"device\" setting\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"training loss:\", train_loss)\n",
    "print(\"validation loss:\", val_loss)\n",
    "\n",
    "# the loss values are relatively high because the model has not yet been trained\n",
    "# for comparison, the loss approaches 0 if the model learns to generate the text tokens as they appear in the training and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a097d8",
   "metadata": {},
   "source": [
    "training an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d768572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                       optimizer, device, num_epochs, \n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # start the main training loop (1 epoch is 1 complete pass over a training set)\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            # reset loss gradients from the previous batch iteration\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            # calculate loss gradients\n",
    "            loss.backward()\n",
    "            # update model weights using loss gradients\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step: 06d}):\"\n",
    "                      f\"train loss {train_loss: .3f} ,\" \n",
    "                      f\"val loss {val_loss: .3f}\"\n",
    "                      )\n",
    "        \n",
    "        # print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen    \n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    # print the training and validation set losses after each model update\n",
    "    # so we can evaluate whether the training improves the model\n",
    "\n",
    "    # dropout is disabled during evaluation for stable and reproducible results\n",
    "    model.eval()\n",
    "\n",
    "    # disables graident tracking, which is not required during evauation, to reduce the computational overhead\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    # take a text snippet(start_context) as input, feeds it to the LLM to generate a text sample using generate_text_simple\n",
    "    # also a convenience function used to track whether the model imporves during the training\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    \n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\",\"\"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "931fd128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step  00000):train loss  9.781 ,val loss  9.933\n",
      "Ep 1 (Step  00005):train loss  8.111 ,val loss  8.339\n",
      "Every effort moves you,,,,,,,,,,,,.\n",
      "Ep 2 (Step  00010):train loss  6.661 ,val loss  7.048\n",
      "Ep 2 (Step  00015):train loss  5.961 ,val loss  6.616\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,, and, and,\n",
      "Ep 3 (Step  00020):train loss  5.726 ,val loss  6.600\n",
      "Ep 3 (Step  00025):train loss  5.201 ,val loss  6.348\n",
      "Every effort moves you, and I had been.\n",
      "Ep 4 (Step  00030):train loss  4.417 ,val loss  6.278\n",
      "Ep 4 (Step  00035):train loss  4.069 ,val loss  6.226\n",
      "Every effort moves you know the\"I he had the donkey and I had the and I had the donkey and down the room, I had\n",
      "Ep 5 (Step  00040):train loss  3.732 ,val loss  6.160\n",
      "Every effort moves you know it was not that the picture--I had the fact by the last I had been--his, and in the\"Oh, and he said, and down the room, and in\n",
      "Ep 6 (Step  00045):train loss  2.850 ,val loss  6.179\n",
      "Ep 6 (Step  00050):train loss  2.427 ,val loss  6.141\n",
      "Every effort moves you know,\" was one of the picture. The--I had a little of a little: \"Yes, and in fact, and in the picture was, and I had been at my elbow and as his pictures, and down the room, I had\n",
      "Ep 7 (Step  00055):train loss  2.104 ,val loss  6.134\n",
      "Ep 7 (Step  00060):train loss  1.882 ,val loss  6.233\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.\"I was no--as! The women had been, in the moment--as Jack himself, as once one had been the donkey, and were, and in his\n",
      "Ep 8 (Step  00065):train loss  1.320 ,val loss  6.238\n",
      "Ep 8 (Step  00070):train loss  0.985 ,val loss  6.242\n",
      "Every effort moves you know,\" was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
      "Ep 9 (Step  00075):train loss  0.717 ,val loss  6.293\n",
      "Ep 9 (Step  00080):train loss  0.541 ,val loss  6.393\n",
      "Every effort moves you?\"\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"He laughed again, and threw back the window-curtains, I had the donkey. \"There were days when I\n",
      "Ep 10 (Step  00085):train loss  0.391 ,val loss  6.452\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "# AdamW optimizer: improves the weight decay approach, to minimize model complexity and prevent overfitting by penalizing larger weights\n",
    "# frequently used in the traning of LLMs\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=0.0004,\n",
    "    weight_decay=0.1\n",
    ")\n",
    "num_epochs = 10\n",
    "train_losses, val_losses,tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57e12189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label='training loss')\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"validation loss\")\n",
    "    ax1.set_xlabel(\"epochs\")\n",
    "    ax1.set_ylabel(\"loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143ad7c0",
   "metadata": {},
   "source": [
    "decoding strategies to control randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26e69493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put the model into evaluation mode to turn off random components (such as dropout)\n",
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fd3677e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75c2dcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature scaling (probabilistic sampling)\n",
    "\n",
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea89afa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])\n",
    "\n",
    "# since the largest logit is 6.75 (pos=3), the generated word is \"forward\" based on vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "581e3660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)\n",
    "\n",
    "# \"forward\" is still the most likely token and will be selected by multinomial most of time but not all the time\n",
    "# this means if we use multinomial (not argmax) function inside the generate_and_print_sample, the LLM would sometimes generate texts\n",
    "# such as every effort moves you \"toward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "679d39d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# temperature greater than 1 will result in more uniformly distributed token probabilities\n",
    "#             smaller than 1 will result in more confident (sharper/peaky) distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "32f18916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temperatures = [1, 0.1, 5] #original, lower, higher\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar( x + i*bar_width, scaled_probas[i],\n",
    "                   bar_width, label=f'Temperature = {T}')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# temp=0.1 results in sharper distribution such that multinomial selects \"forward\" almost 100% of the time (close to argmax)\n",
    "# temp=5 results in more uniform distribution where other tokens are selected more often \n",
    "#         (add more variety to generated text, but also more often results in nonsensical text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d591d647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "top positions: tensor([3, 7, 0])\n",
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n",
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "# top-k approach replaces all nonselected logits with negative infinity values (-inf), \n",
    "# for which prob score of 0 when computing softmax and the remaining prob sum up to 1 \n",
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"top logits:\", top_logits)\n",
    "print(\"top positions:\", top_pos)\n",
    "\n",
    "\n",
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float('-inf')),\n",
    "    other=next_token_logits\n",
    ")\n",
    "print(new_logits)\n",
    "\n",
    "\n",
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bffb5f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify generate_text_simple by combining temperature sampling and top-k sampling\n",
    "\n",
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, \n",
    "             top_k=None, eos_id=None):\n",
    "    \n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :] #same with before, gets logits only focus on the last time step\n",
    "\n",
    "        # filters logits wt top_k sampling\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "        \n",
    "        # apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            # carry out greedy next-token selection as before when temperature scaling is disabled\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28e4fba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output text:\n",
      " Every effort moves youlit terrace.\n",
      "\n",
      "\n",
      "\n",
      "\" he said deprecating laugh\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
    "\n",
    "# the generated text \n",
    "# now is different from the one we previously genereated via generate_simple which was a memorized passage from the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d1477d",
   "metadata": {},
   "source": [
    "loading and saving model weights in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b984268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict is a dict mapping each layer to its parameters\n",
    "# saving model weights via the state_dict\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f8b28bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model weights into a new GPTModel model\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "# switch the model to evaluation mode for inference, disabling the dropout layers of the model\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "163e4283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and optimizer state_dict contents\n",
    "\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "90694662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load saved data\n",
    "\n",
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff72c57",
   "metadata": {},
   "source": [
    "loading pretrained weights from openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4bc3c626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x21aa8ad9820>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# openai originally saved the gpt2 weights via tensorflow\n",
    "import urllib.request\n",
    "\n",
    "url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
    "       \"LLMs-from-scratch/main/ch05/\"\n",
    "       \"01_main-chapter-code/gpt_download.py\")\n",
    "\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0cd3df7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size='124M', models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "036426b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setttings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n",
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(\"setttings:\", settings)\n",
    "print(\"parameter dictionary keys:\", params.keys())\n",
    "print(params['wte'])\n",
    "print(\"token embedding weight tensor dimensions:\", params['wte'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2a0057",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-x1 (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0f4be79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'gpt2-small (124M)'\n",
    "# update model configuarion\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024})\n",
    "NEW_CONFIG.update({\"qkv_bias\": True})\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "67fbcce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if two tensors have the same shape\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
    "                          \"Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c78bd593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the GPTModel initialized with random weighs for pretraining\n",
    "# use openai's model weights to override these random weights\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    # set the model's positional and token embedding weights to those specified in params\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    # iterates over each transformer block in the model\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        # np.split function is used to divide the attention and bias weights\n",
    "        #                   into three equal parts for the query, key and value components\n",
    "\n",
    "        # the assign function will alert us if we try to match two tensors with different dimensions\n",
    "\n",
    "        # attention weights\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        \n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        \n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        \n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        # bias weights        \n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        \n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        \n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        \n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params['blocks'][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        \n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params['blocks'][b]['attn']['c_proj']['b'])\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params['blocks'][b]['mlp']['c_fc']['w'].T)\n",
    "        \n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params['blocks'][b]['mlp']['c_fc']['b'])\n",
    "        \n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params['blocks'][b]['mlp']['c_proj']['w'].T)\n",
    "        \n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params['blocks'][b]['mlp']['c_proj']['b'])\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params['blocks'][b]['ln_1']['g'])\n",
    "        \n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params['blocks'][b]['ln_1']['b'])\n",
    "\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params['blocks'][b]['ln_2']['g'])\n",
    "        \n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params['blocks'][b]['ln_2']['b'])\n",
    "        \n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params['g'])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params['b'])\n",
    "    # weight tying: the original gpt model by openai reused the token embedding weights in the output layer\n",
    "    #               to reduce the total number of parameters\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params['wte'])    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "75dbd6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d2e53c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output text:\n",
      " Every effort moves you toward finding an ideal new way to practice something!\n",
      "\n",
      "What makes us want to be on top of that?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "print(\"output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
    "\n",
    "# with loaded weights, the model can produce more coherent text now."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
